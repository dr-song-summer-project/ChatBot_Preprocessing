{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "카테고리 분류 모델 학습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLIhGu+6BEBJ1lL2VPudAn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dr-song-summer-project/ChatBot_Preprocessing/blob/main/AI/%EC%B9%B4%ED%85%8C%EA%B3%A0%EB%A6%AC_%EB%B6%84%EB%A5%98_%EB%AA%A8%EB%8D%B8_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "FEllAxINLtg2",
        "outputId": "783b3a2e-3861-476b-f918-984db314e491"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O56KbUMdLyLm",
        "outputId": "ae25ca8d-6edc-4891-b354-a2ec5616b058"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEYkBKpMLzGO"
      },
      "source": [
        "from sklearn.datasets import load_files\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import konlpy\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(777) #하이퍼파라미터 튜닝을 위해 실행시 마다 변수가 같은 초기값 가지게 하기\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "sys.getdefaultencoding()\n",
        "\n",
        "def clean_korean_documents(documents):\n",
        "    #텍스트 정제 (HTML 태그 제거)\n",
        "    for i, document in enumerate(documents):\n",
        "        document = BeautifulSoup(document, 'html.parser').text \n",
        "        documents[i] = document\n",
        "\n",
        "    #텍스트 정제 (특수기호 제거)\n",
        "    for i, document in enumerate(documents):\n",
        "        document = re.sub(r'[^ ㄱ-ㅣ가-힣]', '', document) #특수기호 제거, 정규 표현식\n",
        "        documents[i] = document\n",
        "\n",
        "    #텍스트 정제 (형태소 분석)\n",
        "    for i, document in enumerate(documents):\n",
        "        okt = konlpy.tag.Okt()\n",
        "        clean_words = []\n",
        "        for word in okt.pos(document, stem=True): #어간 추출\n",
        "            if word[1] in ['Noun', 'Verb', 'Adjective']: #명사, 동사, 형용사\n",
        "                clean_words.append(word[0])\n",
        "        document = ' '.join(clean_words)\n",
        "        documents[i] = document\n",
        "\n",
        "    #텍스트 정제 (불용어 제거)\n",
        "    df = pd.read_csv('https://raw.githubusercontent.com/cranberryai/todak_todak_python/master/machine_learning_text/clean_korean_documents/korean_stopwords.txt', header=None)\n",
        "    df[0] = df[0].apply(lambda x: x.strip())\n",
        "    stopwords = df[0].to_numpy()\n",
        "    nltk.download('punkt')\n",
        "    for i, document in enumerate(documents):\n",
        "        clean_words = [] \n",
        "        for word in nltk.tokenize.word_tokenize(document): \n",
        "            if word not in stopwords: #불용어 제거\n",
        "                clean_words.append(word)\n",
        "        documents[i] = ' '.join(clean_words)  \n",
        "\n",
        "    return documents\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7yb3-EpL0w2",
        "outputId": "0a3d55c8-faab-4761-aabc-f9ec28644cb5"
      },
      "source": [
        "##########데이터 로드\n",
        "\n",
        "naver_news = load_files('/gdrive/My Drive/Colab Notebooks/Src/newsData/newsData', shuffle=True)\n",
        "labels = ['정치', '경제', '사회', '생활/문화', '세계', '기술/IT', '연예', '스포츠']\n",
        "\n",
        "# naver_news = load_files('/gdrive/My Drive/Colab Notebooks/Src/QueryData', shuffle=True, encoding='CP949')\n",
        "# labels = []\n",
        "# for i in range(0, 20):\n",
        "#   labels.append(str(i))\n",
        "\n",
        "##########데이터 분석\n",
        "\n",
        "##########데이터 전처리\n",
        "\n",
        "x_data = naver_news.data\n",
        "y_data = naver_news.target\n",
        "# print(len(x_data)) #1600\n",
        "x_data = x_data[:800] #데이터를 800개로 제한\n",
        "y_data = y_data[:800]\n",
        "\n",
        "print(x_data[0]) #b'\\xed\\x83\\x9c\\xec\\x96\\x91\\xea\\xb4\\x91\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\xb6\\xa9\\xec\\xa0\\x84\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xe2\\x80\\x98\\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X ...'\n",
        "print(y_data[0]) #5\n",
        "\n",
        "x_data = [x.decode('utf-8') for x in x_data] #바이트를 문자열로 바꾸기\n",
        "print(x_data[0]) #태양광으로 충전되는 ‘아이폰X 테슬라’ (지디넷코리아=이정현 기자)도널드 트럼프 미국 대통령과 푸틴 러시아 대통령의 초상화를 새긴 황금 아이폰을 출시해 ...\n",
        "\n",
        "x_data = clean_korean_documents(x_data) #텍스트 정제\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer() \n",
        "tokenizer.fit_on_texts(x_data)\n",
        "x_data = tokenizer.texts_to_sequences(x_data) #정수 인코딩\n",
        "sequence_length = 200\n",
        "x_data = tf.keras.preprocessing.sequence.pad_sequences(x_data, maxlen=sequence_length) #길이 맞추기\n",
        "\n",
        "y_data = tf.keras.utils.to_categorical(y_data)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777, stratify=y_data)\n",
        "\n",
        "\n",
        "##########모델 생성\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(sequence_length,))\n",
        "net = tf.keras.layers.Dense(units=32, activation='relu')(input)\n",
        "net = tf.keras.layers.Dense(units=32, activation='relu')(net)\n",
        "net = tf.keras.layers.Dense(units=8, activation='softmax')(net)\n",
        "model = tf.keras.models.Model(input, net)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\xed\\x83\\x9c\\xec\\x96\\x91\\xea\\xb4\\x91\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\xb6\\xa9\\xec\\xa0\\x84\\xeb\\x90\\x98\\xeb\\x8a\\x94 \\xe2\\x80\\x98\\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X \\xed\\x85\\x8c\\xec\\x8a\\xac\\xeb\\x9d\\xbc\\xe2\\x80\\x99\\t(\\xec\\xa7\\x80\\xeb\\x94\\x94\\xeb\\x84\\xb7\\xec\\xbd\\x94\\xeb\\xa6\\xac\\xec\\x95\\x84=\\xec\\x9d\\xb4\\xec\\xa0\\x95\\xed\\x98\\x84 \\xea\\xb8\\xb0\\xec\\x9e\\x90)\\xeb\\x8f\\x84\\xeb\\x84\\x90\\xeb\\x93\\x9c \\xed\\x8a\\xb8\\xeb\\x9f\\xbc\\xed\\x94\\x84 \\xeb\\xaf\\xb8\\xea\\xb5\\xad \\xeb\\x8c\\x80\\xed\\x86\\xb5\\xeb\\xa0\\xb9\\xea\\xb3\\xbc \\xed\\x91\\xb8\\xed\\x8b\\xb4 \\xeb\\x9f\\xac\\xec\\x8b\\x9c\\xec\\x95\\x84 \\xeb\\x8c\\x80\\xed\\x86\\xb5\\xeb\\xa0\\xb9\\xec\\x9d\\x98 \\xec\\xb4\\x88\\xec\\x83\\x81\\xed\\x99\\x94\\xeb\\xa5\\xbc \\xec\\x83\\x88\\xea\\xb8\\xb4 \\xed\\x99\\xa9\\xea\\xb8\\x88 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0\\xec\\x9d\\x84 \\xec\\xb6\\x9c\\xec\\x8b\\x9c\\xed\\x95\\xb4 \\xed\\x99\\x94\\xec\\xa0\\x9c\\xeb\\xa5\\xbc \\xeb\\xaa\\xa8\\xec\\x95\\x98\\xeb\\x8d\\x98 \\xeb\\x9f\\xac\\xec\\x8b\\x9c\\xec\\x95\\x84 \\xec\\x97\\x85\\xec\\xb2\\xb4 \\xec\\xba\\x90\\xeb\\xb9\\x84\\xec\\x95\\x84(Caviar)\\xea\\xb0\\x80 \\xec\\x9d\\xb4\\xeb\\xb2\\x88\\xec\\x97\\x94 \\xed\\x83\\x9c\\xec\\x96\\x91\\xea\\xb4\\x91 \\xec\\xb6\\xa9\\xec\\xa0\\x84\\xec\\x9d\\xb4 \\xea\\xb0\\x80\\xeb\\x8a\\xa5\\xed\\x95\\x9c \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X\\xeb\\xa5\\xbc \\xed\\x8c\\x90\\xeb\\xa7\\xa4\\xed\\x95\\x9c\\xeb\\x8b\\xa4\\xea\\xb3\\xa0\\xc2\\xa0IT\\xeb\\xa7\\xa4\\xec\\xb2\\xb4 \\xeb\\x8d\\x94\\xeb\\xb2\\x84\\xec\\xa7\\x80\\xea\\xb0\\x80 16\\xec\\x9d\\xbc(\\xed\\x98\\x84\\xec\\xa7\\x80\\xec\\x8b\\x9c\\xea\\xb0\\x84) \\xeb\\xb3\\xb4\\xeb\\x8f\\x84\\xed\\x96\\x88\\xeb\\x8b\\xa4.\\n\\n\\n\\xec\\x9d\\xb4 \\xec\\x97\\x85\\xec\\xb2\\xb4\\xeb\\x8a\\x94 \\xec\\xa3\\xbc\\xeb\\xa1\\x9c \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0, \\xec\\x95\\xa0\\xed\\x94\\x8c\\xec\\x9b\\x8c\\xec\\xb9\\x98 \\xeb\\x93\\xb1\\xec\\x9d\\x98\\xc2\\xa0IT\\xc2\\xa0\\xec\\xa0\\x9c\\xed\\x92\\x88\\xeb\\x93\\xa4\\xec\\x9d\\x84 \\xea\\xb8\\x88\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x9e\\xa5\\xec\\x8b\\x9d\\xed\\x95\\x98\\xea\\xb3\\xa0 \\xea\\xb0\\x9c\\xec\\xa1\\xb0\\xed\\x95\\xb4 \\xea\\xb3\\xa0\\xea\\xb0\\x80\\xec\\x97\\x90 \\xed\\x8c\\x90\\xeb\\xa7\\xa4\\xed\\x95\\x98\\xeb\\x8a\\x94 \\xec\\x97\\x85\\xec\\xb2\\xb4\\xeb\\x8b\\xa4.\\n\\n\\xec\\x9d\\xb4 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0\\xec\\x9d\\x98 \\xec\\x9d\\xb4\\xeb\\xa6\\x84\\xec\\x9d\\x80 \\xe2\\x80\\x98\\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X \\xed\\x85\\x8c\\xec\\x8a\\xac\\xeb\\x9d\\xbc(Tesla)\\xe2\\x80\\x99. \\xec\\x9d\\xb4 \\xec\\xa0\\x9c\\xed\\x92\\x88\\xec\\x9d\\x98 \\xeb\\x92\\xb7\\xeb\\xa9\\xb4\\xec\\x97\\x90\\xeb\\x8a\\x94 \\xed\\x83\\x9c\\xec\\x96\\x91 \\xec\\xa0\\x84\\xec\\xa7\\x80 \\xed\\x8c\\xa8\\xeb\\x84\\x90\\xec\\x9d\\xb4 \\xec\\x9e\\x88\\xec\\x96\\xb4 \\xec\\x8a\\xa4\\xeb\\xa7\\x88\\xed\\x8a\\xb8\\xed\\x8f\\xb0\\xec\\x9d\\x84 \\xeb\\x92\\xa4\\xec\\xa7\\x91\\xec\\x96\\xb4 \\xeb\\x86\\x93\\xea\\xb8\\xb0\\xeb\\xa7\\x8c \\xed\\x95\\x98\\xeb\\xa9\\xb4 \\xec\\xb6\\xa9\\xec\\xa0\\x84\\xec\\x9d\\xb4 \\xeb\\x90\\x98\\xec\\x96\\xb4 \\xeb\\xb3\\xb4\\xec\\xa1\\xb0 \\xeb\\xb0\\xb0\\xed\\x84\\xb0\\xeb\\xa6\\xac \\xed\\x98\\x95\\xed\\x83\\x9c\\xeb\\xa1\\x9c \\xec\\x82\\xac\\xec\\x9a\\xa9\\xed\\x95\\xa0 \\xec\\x88\\x98 \\xec\\x9e\\x88\\xeb\\x8b\\xa4.\\n\\n\\n\\xeb\\xac\\xbc\\xeb\\xa1\\xa0, \\xec\\x9d\\xb4 \\xec\\x97\\x85\\xec\\xb2\\xb4\\xea\\xb0\\x80 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0\\xec\\x9d\\x84 \\xec\\xa7\\x81\\xec\\xa0\\x91 \\xeb\\xa7\\x8c\\xeb\\x93\\x9c\\xeb\\x8a\\x94 \\xea\\xb2\\x83\\xec\\x9d\\xb4 \\xec\\x95\\x84\\xeb\\x8b\\x88\\xea\\xb8\\xb0 \\xeb\\x95\\x8c\\xeb\\xac\\xb8\\xec\\x97\\x90 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X\\xec\\x97\\x90 \\xed\\x83\\x91\\xec\\x9e\\xac\\xeb\\x90\\x9c \\xed\\x83\\x9c\\xec\\x96\\x91\\xea\\xb4\\x91 \\xec\\xb6\\xa9\\xec\\xa0\\x84 \\xea\\xb8\\xb0\\xeb\\x8a\\xa5\\xec\\x9d\\x80 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0\\xec\\x97\\x90 \\xec\\xa7\\x81\\xec\\xa0\\x91 \\xeb\\x82\\xb4\\xec\\x9e\\xa5\\xeb\\x90\\x98\\xec\\x96\\xb4 \\xec\\x9e\\x88\\xeb\\x8a\\x94 \\xed\\x98\\x95\\xed\\x83\\x9c\\xea\\xb0\\x80 \\xec\\x95\\x84\\xeb\\x8b\\x8c \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0 \\xeb\\xb0\\x94\\xea\\xb9\\xa5 \\xec\\xaa\\xbd\\xec\\x97\\x90 \\xec\\xbc\\x80\\xec\\x9d\\xb4\\xec\\x8a\\xa4 \\xed\\x98\\x95\\xed\\x83\\x9c\\xeb\\xa1\\x9c \\xed\\x83\\x91\\xec\\x9e\\xac\\xeb\\x90\\x9c\\xeb\\x8b\\xa4. \\xeb\\x98\\x90, \\xec\\xba\\x90\\xeb\\xb9\\x84\\xec\\x95\\x84\\xeb\\x8a\\x94 \\xea\\xb7\\xb8 \\xeb\\x8f\\x99\\xec\\x95\\x88 \\xec\\xa0\\x9c\\xea\\xb3\\xb5\\xed\\x96\\x88\\xeb\\x8d\\x98\\xc2\\xa0IT\\xc2\\xa0\\xec\\xa0\\x9c\\xed\\x92\\x88\\xeb\\x93\\xa4\\xea\\xb3\\xbc \\xeb\\xa7\\x88\\xec\\xb0\\xac\\xea\\xb0\\x80\\xec\\xa7\\x80\\xeb\\xa1\\x9c \\xea\\xb3\\xa0\\xea\\xb8\\x89\\xec\\x8a\\xa4\\xeb\\x9f\\xac\\xec\\x9b\\x80\\xec\\x9d\\x84 \\xea\\xb7\\xb9\\xeb\\x8c\\x80\\xed\\x99\\x94 \\xed\\x95\\x98\\xea\\xb8\\xb0 \\xec\\x9c\\x84\\xed\\x95\\xb4 \\xeb\\x85\\xb8\\xeb\\xa0\\xa5\\xed\\x96\\x88\\xeb\\x8b\\xa4. \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0 \\xeb\\x92\\xb7\\xeb\\xa9\\xb4 \\xeb\\xaa\\xa8\\xec\\x84\\x9c\\xeb\\xa6\\xac\\xec\\x99\\x80 \\xed\\x9b\\x84\\xeb\\xa9\\xb4 \\xec\\xb9\\xb4\\xeb\\xa9\\x94\\xeb\\x9d\\xbc \\xed\\x85\\x8c\\xeb\\x91\\x90\\xeb\\xa6\\xac \\xeb\\x93\\xb1 \\xea\\xb3\\xb3\\xea\\xb3\\xb3\\xec\\x9d\\x84 24k \\xea\\xb8\\x88\\xec\\x9c\\xbc\\xeb\\xa1\\x9c \\xec\\x9e\\xa5\\xec\\x8b\\x9d\\xed\\x96\\x88\\xeb\\x8b\\xa4.\\n\\n\\xec\\x9d\\xb4 \\xec\\xa0\\x9c\\xed\\x92\\x88\\xec\\x9d\\x80 999\\xeb\\x8c\\x80 \\xed\\x95\\x9c\\xec\\xa0\\x95 \\xec\\x83\\x9d\\xec\\x82\\xb0\\xeb\\x90\\x9c\\xeb\\x8b\\xa4. 64GB\\xc2\\xa0\\xeb\\xaa\\xa8\\xeb\\x8d\\xb8 \\xec\\x95\\x84\\xec\\x9d\\xb4\\xed\\x8f\\xb0X \\xed\\x85\\x8c\\xec\\x8a\\xac\\xeb\\x9d\\xbc\\xec\\x9d\\x98 \\xea\\xb0\\x80\\xea\\xb2\\xa9\\xec\\x9d\\x80 4,555\\xeb\\x8b\\xac\\xeb\\x9f\\xac(\\xec\\x95\\xbd 490\\xeb\\xa7\\x8c \\xec\\x9b\\x90), 256GB\\xeb\\xaa\\xa8\\xeb\\x8d\\xb8\\xec\\x9d\\x98 \\xea\\xb2\\xbd\\xec\\x9a\\xb0 4,805\\xeb\\x8b\\xac\\xeb\\x9f\\xac(\\xec\\x95\\xbd 517\\xeb\\xa7\\x8c\\xec\\x9b\\x90)\\xeb\\x8b\\xa4.'\n",
            "5\n",
            "태양광으로 충전되는 ‘아이폰X 테슬라’\t(지디넷코리아=이정현 기자)도널드 트럼프 미국 대통령과 푸틴 러시아 대통령의 초상화를 새긴 황금 아이폰을 출시해 화제를 모았던 러시아 업체 캐비아(Caviar)가 이번엔 태양광 충전이 가능한 아이폰X를 판매한다고 IT매체 더버지가 16일(현지시간) 보도했다.\n",
            "\n",
            "\n",
            "이 업체는 주로 아이폰, 애플워치 등의 IT 제품들을 금으로 장식하고 개조해 고가에 판매하는 업체다.\n",
            "\n",
            "이 아이폰의 이름은 ‘아이폰X 테슬라(Tesla)’. 이 제품의 뒷면에는 태양 전지 패널이 있어 스마트폰을 뒤집어 놓기만 하면 충전이 되어 보조 배터리 형태로 사용할 수 있다.\n",
            "\n",
            "\n",
            "물론, 이 업체가 아이폰을 직접 만드는 것이 아니기 때문에 아이폰X에 탑재된 태양광 충전 기능은 아이폰에 직접 내장되어 있는 형태가 아닌 아이폰 바깥 쪽에 케이스 형태로 탑재된다. 또, 캐비아는 그 동안 제공했던 IT 제품들과 마찬가지로 고급스러움을 극대화 하기 위해 노력했다. 아이폰 뒷면 모서리와 후면 카메라 테두리 등 곳곳을 24k 금으로 장식했다.\n",
            "\n",
            "이 제품은 999대 한정 생산된다. 64GB 모델 아이폰X 테슬라의 가격은 4,555달러(약 490만 원), 256GB모델의 경우 4,805달러(약 517만원)다.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCh4Kb9CL16m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28abd3af-a4b7-4712-ec07-74ec6b48ec9f"
      },
      "source": [
        "##########모델 학습\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test)) \n",
        "\n",
        "##########모델 검증\n",
        "\n",
        "##########모델 예측\n",
        "\n",
        "x_test = np.array([\n",
        "     '우리은행, 인공지능 기반 시장예측시스템 구축 추진'\n",
        "])\n",
        "x_test = clean_korean_documents(x_test) #텍스트 정제\n",
        "x_test = tokenizer.texts_to_sequences(x_test) #정수 인코딩\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=sequence_length) #길이 맞추기\n",
        "\n",
        "y_predict = model.predict(x_test)\n",
        "\n",
        "label = labels[y_predict[0].argmax()]\n",
        "confidence = y_predict[0][y_predict[0].argmax()]\n",
        "print(label, confidence) #"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 2329.0676 - accuracy: 0.1393 - val_loss: 1713.7452 - val_accuracy: 0.1125\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1032.8552 - accuracy: 0.1446 - val_loss: 1042.3944 - val_accuracy: 0.1250\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 632.8298 - accuracy: 0.1696 - val_loss: 777.6588 - val_accuracy: 0.1125\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 453.0080 - accuracy: 0.1875 - val_loss: 657.7955 - val_accuracy: 0.1208\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 337.1630 - accuracy: 0.2482 - val_loss: 572.7471 - val_accuracy: 0.1125\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 260.0916 - accuracy: 0.2786 - val_loss: 521.3692 - val_accuracy: 0.0917\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 201.6629 - accuracy: 0.3214 - val_loss: 477.5094 - val_accuracy: 0.0958\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 160.0782 - accuracy: 0.3625 - val_loss: 454.2975 - val_accuracy: 0.0958\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 128.4091 - accuracy: 0.3786 - val_loss: 423.2824 - val_accuracy: 0.1125\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 104.4802 - accuracy: 0.4196 - val_loss: 404.7959 - val_accuracy: 0.1208\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 86.9736 - accuracy: 0.4643 - val_loss: 388.3224 - val_accuracy: 0.1250\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 72.3339 - accuracy: 0.4768 - val_loss: 375.2549 - val_accuracy: 0.1125\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 60.5243 - accuracy: 0.5232 - val_loss: 370.8630 - val_accuracy: 0.1208\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 52.0968 - accuracy: 0.5304 - val_loss: 351.2611 - val_accuracy: 0.1125\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 46.8284 - accuracy: 0.5179 - val_loss: 340.7748 - val_accuracy: 0.1000\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 38.6218 - accuracy: 0.5464 - val_loss: 333.0220 - val_accuracy: 0.1083\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 32.4636 - accuracy: 0.5804 - val_loss: 332.2401 - val_accuracy: 0.1125\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 27.9528 - accuracy: 0.5946 - val_loss: 324.3083 - val_accuracy: 0.1042\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 25.0791 - accuracy: 0.6054 - val_loss: 322.2700 - val_accuracy: 0.1083\n",
            "Epoch 20/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 21.0891 - accuracy: 0.6304 - val_loss: 312.4385 - val_accuracy: 0.1042\n",
            "Epoch 21/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 19.6219 - accuracy: 0.6321 - val_loss: 309.2821 - val_accuracy: 0.1042\n",
            "Epoch 22/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 16.1882 - accuracy: 0.6661 - val_loss: 306.7731 - val_accuracy: 0.0958\n",
            "Epoch 23/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 14.5657 - accuracy: 0.6679 - val_loss: 302.8337 - val_accuracy: 0.1000\n",
            "Epoch 24/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 14.1311 - accuracy: 0.6732 - val_loss: 301.7792 - val_accuracy: 0.1208\n",
            "Epoch 25/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 12.5123 - accuracy: 0.7054 - val_loss: 297.3948 - val_accuracy: 0.1042\n",
            "Epoch 26/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 11.8932 - accuracy: 0.6857 - val_loss: 295.4118 - val_accuracy: 0.1333\n",
            "Epoch 27/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 10.9774 - accuracy: 0.6911 - val_loss: 293.8260 - val_accuracy: 0.1167\n",
            "Epoch 28/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.6343 - accuracy: 0.7179 - val_loss: 293.6798 - val_accuracy: 0.1292\n",
            "Epoch 29/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 9.1455 - accuracy: 0.7018 - val_loss: 292.5456 - val_accuracy: 0.1333\n",
            "Epoch 30/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.7566 - accuracy: 0.6946 - val_loss: 289.4419 - val_accuracy: 0.1333\n",
            "Epoch 31/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 8.1877 - accuracy: 0.7161 - val_loss: 284.0792 - val_accuracy: 0.1417\n",
            "Epoch 32/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 7.2807 - accuracy: 0.7304 - val_loss: 281.0476 - val_accuracy: 0.1292\n",
            "Epoch 33/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 6.7700 - accuracy: 0.7429 - val_loss: 282.1738 - val_accuracy: 0.1333\n",
            "Epoch 34/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 6.1089 - accuracy: 0.7482 - val_loss: 279.0841 - val_accuracy: 0.1417\n",
            "Epoch 35/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 5.6464 - accuracy: 0.7321 - val_loss: 274.9940 - val_accuracy: 0.1458\n",
            "Epoch 36/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 5.6010 - accuracy: 0.7518 - val_loss: 277.0956 - val_accuracy: 0.1417\n",
            "Epoch 37/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 5.4275 - accuracy: 0.7464 - val_loss: 276.1915 - val_accuracy: 0.1417\n",
            "Epoch 38/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 6.1354 - accuracy: 0.7214 - val_loss: 279.3892 - val_accuracy: 0.1542\n",
            "Epoch 39/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 5.3004 - accuracy: 0.7500 - val_loss: 277.2506 - val_accuracy: 0.1375\n",
            "Epoch 40/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 4.6425 - accuracy: 0.7536 - val_loss: 276.7285 - val_accuracy: 0.1292\n",
            "Epoch 41/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 4.0626 - accuracy: 0.7607 - val_loss: 273.0224 - val_accuracy: 0.1333\n",
            "Epoch 42/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 4.1647 - accuracy: 0.7768 - val_loss: 274.0364 - val_accuracy: 0.1417\n",
            "Epoch 43/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.5278 - accuracy: 0.7821 - val_loss: 271.6169 - val_accuracy: 0.1375\n",
            "Epoch 44/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.5569 - accuracy: 0.7839 - val_loss: 270.3760 - val_accuracy: 0.1333\n",
            "Epoch 45/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.6005 - accuracy: 0.7804 - val_loss: 271.4445 - val_accuracy: 0.1417\n",
            "Epoch 46/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.4347 - accuracy: 0.7661 - val_loss: 267.1403 - val_accuracy: 0.1458\n",
            "Epoch 47/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.5924 - accuracy: 0.7679 - val_loss: 267.4369 - val_accuracy: 0.1500\n",
            "Epoch 48/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.3168 - accuracy: 0.7732 - val_loss: 269.8168 - val_accuracy: 0.1417\n",
            "Epoch 49/50\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 3.2505 - accuracy: 0.7661 - val_loss: 262.9896 - val_accuracy: 0.1417\n",
            "Epoch 50/50\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 3.1539 - accuracy: 0.7554 - val_loss: 264.1077 - val_accuracy: 0.1542\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "세계 0.9999999\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}